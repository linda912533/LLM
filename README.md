# Large Language Model (LLM)
This is the space for some practices and tutorials about LLM, including the following topics

Each item contains one colab notebook and its python file

1. Loading LLMs, create pipelines and create prompts for models
2. Running an LLM, contextualized word embeddings, recommending with embeddings
3. Some details while using Transformer
4. Text classification, classification with generative models (enc-dec models/GPT)
5. Text Clustering and Topic Modeling (BERTopic with OpenAI GPT3.5)
6. Prompt engineering (chain-prompting and chain-of-thought)
7. Some text generation techniques (quantized model with LangChain, multiple chains, remembering conversations and agent for creating a system of LLMs)
8. Semantic search (dense retrieval and reranking) and retrieval-augmented generation (RAG) with an LLM API
9. Multimodals LLMs (SBERT, BLIP-2 for image captioning and visual question answering) and text event widget
10. Train and fine-tuning an embedding model (Supervised/Augmented SBERT/Unsupervised Learning)
